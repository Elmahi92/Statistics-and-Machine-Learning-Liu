{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "‚û°Ô∏è Make sure that you have read the **[rules for hand-in assignments](https://www.ida.liu.se/~TDDE16/exam.en.shtml#handins)** and the **[policy on cheating and plagiarism](https://www.ida.liu.se/~TDDE16/exam.en.shtml#cheating)** before starting with this lab.\n",
    "\n",
    "‚û°Ô∏è Make sure you fill in any cells (and _only_ those cells) that say **`YOUR CODE HERE`** or **YOUR ANSWER HERE**, and do _not_ modify any of the other cells.\n",
    "\n",
    "‚û°Ô∏è **Before you submit your lab, make sure everything runs as expected.** For this, _restart the kernel_ and _run all cells_ from top to bottom. In Jupyter Notebook version 7 or higher, you can do this via \"Run$\\rightarrow$Restart Kernel and Run All Cells...\" in the menu (or the \"‚è©\" button in the toolbar).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# L3: Text clustering and topic modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Text clustering groups documents in such a way that documents within a group are more &lsquo;similar&rsquo; to other documents in the cluster than to documents not in the cluster. The exact definition of what &lsquo;similar&rsquo; means in this context varies across applications and clustering algorithms.\n",
    "\n",
    "In this lab you will experiment with both hard and soft clustering techniques. More specifically, in the first part you will be using the $k$-means algorithm, and in the second part you will be using a topic model based on the Latent Dirichlet Allocation (LDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7807a0c189a6c7ed59c8e31b90cdded6",
     "grade": false,
     "grade_id": "cell-c4776a1666a48ddd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define some helper functions that are used in this notebook\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "def success():\n",
    "    display(HTML('<div class=\"alert alert-success\"><strong>Solution appears correct!</strong></div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Hard clustering data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The raw data for the hard clustering part of this lab is a collection of product reviews. We have preprocessed the data by tokenization and lowercasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "007298be2cbb2c02ebe809b6a44f0f48",
     "grade": false,
     "grade_id": "cell-59c1ac1d68e6c524",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bz2\n",
    "\n",
    "with bz2.open('reviews.json.bz2') as source:\n",
    "    df = pd.read_json(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "When you inspect the data frame, you can see that there are three labelled columns: `category` (the product category), `sentiment` (whether the product review was classified as &lsquo;positive&rsquo; or &lsquo;negative&rsquo; towards the product), and `text` (the space-separated text of the review)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  category sentiment                                               text\n0    music       neg  i bought this album because i loved the title ...\n1    music       neg  i was misled and thought i was buying the enti...\n2    books       neg  i have introduced many of my ell , high school...\n3    books       pos  anything you purchase in the left behind serie...\n4      dvd       pos  i loved these movies , and i cant wiat for the...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>sentiment</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>music</td>\n      <td>neg</td>\n      <td>i bought this album because i loved the title ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>music</td>\n      <td>neg</td>\n      <td>i was misled and thought i was buying the enti...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>books</td>\n      <td>neg</td>\n      <td>i have introduced many of my ell , high school...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>books</td>\n      <td>pos</td>\n      <td>anything you purchase in the left behind serie...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dvd</td>\n      <td>pos</td>\n      <td>i loved these movies , and i cant wiat for the...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Problem 1: K-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Your first task is to cluster the product review data using a tf‚Äìidf vectorizer and a $k$-means clusterer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task 1.1\n",
    "\n",
    "Start by doing the vectorization. In connection with vectorization, you should also filter out standard English stop words. While you could use [spaCy](https://spacy.io/) for this task, here it suffices to use the word list implemented in [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html).\n",
    "\n",
    "After running the following cell:\n",
    "- `vectorizer` should contain the vectorizer fitted on `df['text']`\n",
    "- `reviews` should contain the vectorized `df['text']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "217b844f6aadf1c8e9e02c15f8a9fc13",
     "grade": false,
     "grade_id": "cell-66e447662e958a44",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We'll use class sklearn.feature_extraction.text.TfidfVectorizer(*, input='content', encoding='utf-8', decode_error='strict', strip_accents=None, lowercase=True, preprocessor=None, tokenizer=None, analyzer='word', stop_words=None, token_pattern='(?u)\\b\\w\\w+\\b', ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, vocabulary=None, binary=False, dtype=<class 'numpy.float64'>, norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "# Example >>> vectorizer = TfidfVectorizer()\n",
    "#  >>> X = vectorizer.fit_transform(corpus)\n",
    "# We define out stop words by setting the parameter stop_words = \"english\"\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "reviews= vectorizer.fit_transform(df[\"text\"])\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### ü§û Test your code\n",
    "\n",
    "If you used the English stop word list from scikit-learn, then the resulting vocabulary should have 46,619 entries.  You can check this by running the following code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8fa82a4915bf8f9efc24e3b73e83a61c",
     "grade": true,
     "grade_id": "cell-b57497f350b4805e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div class=\"alert alert-success\"><strong>Solution appears correct!</strong></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Check that the vectorized text column has the right dimensions.\"\"\"\n",
    "\n",
    "assert reviews.shape == (11914, 46619), f\"Wrong dimensions: {reviews.shape}\"\n",
    "success()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<1x46619 sparse matrix of type '<class 'numpy.float64'>'\n\twith 57 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task 1.2\n",
    "\n",
    "Next, cluster the vectorized data. Before doing so, you should read the documentation of the [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) class, which is scikit-learn&rsquo;s implementation of the $k$-means algorithm. As you can see, this class has several parameters that you can tweak. For now, the only parameter that you will have to set is the number of clusters. Start with $k=3$.\n",
    "\n",
    "**Tip:** Training $k$-means models will take some time. To speed things up, you can use the `n_init` parameter to control the number of times that the clustering is re-computed with different initial values. The default value for this parameter is 10; here and in the rest of this lab, you may want to set this to a lower value, or simply to \"auto\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f795b44fb710deb8ec6557222fe3186f",
     "grade": true,
     "grade_id": "cell-17f7b79dee452c3d",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "solution"
    ],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fit_kmeans(data, n_clusters):\n",
    "    \"\"\"Fit a k-means classifier to some data.\n",
    "\n",
    "    Arguments:\n",
    "        data: The vectorized data to train the classifier on.\n",
    "        n_clusters (int): The number of clusters.\n",
    "\n",
    "    Returns:\n",
    "        The trained k-means classifier.\n",
    "    \"\"\"\n",
    "    # class sklearn.cluster.KMeans(n_clusters=8, *, init='k-means++', n_init='warn', max_iter=300, tol=0.0001, verbose=0, random_state=None, copy_x=True, algorithm='lloyd')\n",
    "    # Example >>> X = np.array([[1, 2], [1, 4], [1, 0],   [10, 2], [10, 4], [10, 0]]) >>> kmeans = KMeans(n_clusters=2, random_state=0, n_init=\"auto\").fit(X) >>> kmeans.labels_\n",
    "    X = data\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=5).fit(X)\n",
    "    return kmeans\n",
    "\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To sanity-check your clustering, create a bar plot with the number of documents per cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40b71623600900c4911b5c12c3aa597e",
     "grade": true,
     "grade_id": "cell-d54820cd63b959ee",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "solution"
    ],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_cluster_size(kmeans):\n",
    "    \"\"\"Produce & display a bar plot with the number of documents per cluster.\n",
    "\n",
    "    Arguments:\n",
    "        kmeans: The trained k-means classifier.\n",
    "    \"\"\"\n",
    "    unique, counts = np.unique(kmeans.labels_, return_counts=True)\n",
    "    return plt.bar(unique, counts,color='#2E9947')\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### ü§û Test your code\n",
    "\n",
    "The following cell shows how your code should run.  The output of the cell should be the bar plot of the cluster sizes.  Note that sizes may vary considerable between clusters and among different random seeds, so there is no single ‚Äúcorrect‚Äù output here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be43147fbe32384e27725a250f90f8ed",
     "grade": false,
     "grade_id": "cell-d19c0d777f6bc8c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<BarContainer object of 3 artists>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kmeans = fit_kmeans(reviews, 3)\n",
    "plot_cluster_size(kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Problem 2: Summarize clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Once you have a clustering, you can try to see whether it is meaningful. One useful technique in that context is to generate a **summary** for each cluster by extracting the $n$ highest-weighted terms from the centroid of each cluster. Your next task is to implement this approach.\n",
    "\n",
    "(Hint: You will need to figure out how to use the vectorizer to convert indices back into the terms they represent.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_cluster_summaries(kmeans, vectorizer, top_n):\n",
    "    \"\"\"Compute the top_n highest-weighted terms from the centroid of each cluster.\n",
    "\n",
    "    Arguments:\n",
    "        kmeans: The trained k-means classifier.\n",
    "        vectorizer: The fitted vectorizer; needed to obtain the actual terms\n",
    "                    belonging to the items in the cluster.\n",
    "        top_n: The number of terms to return for each cluster.\n",
    "\n",
    "    Returns:\n",
    "        A list of length k, where k is the number of clusters. Each item in the list\n",
    "        should be a list of length `top_n` with the highest-weighted terms from that\n",
    "        cluster. Example:\n",
    "          [[\"first\", \"foo\", ...], [\"second\", \"bar\", ...], [\"third\", \"baz\", ...]]\n",
    "    \"\"\"\n",
    "    list = []\n",
    "    for i in range(3):\n",
    "        c = kmeans.cluster_centers_[i]\n",
    "        ind = np.argpartition(c, -top_n)[-top_n:]\n",
    "        sorted_ind = np.sort(ind)[::-1]\n",
    "        voc = vectorizer.vocabulary_\n",
    "        words = [key for key, value in voc.items() if value in sorted_ind]\n",
    "        list.append(words)\n",
    "\n",
    "    return list\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ü§û Test your code\n",
    "\n",
    "The following cell runs your code with `top_n=10`, checks that the returned lists have the expected dimensions, and prints the summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f7b0b2a80b8227e4232eb58af9dee4f",
     "grade": true,
     "grade_id": "cell-068cd41672d89838",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "solution"
    ],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div class=\"alert alert-success\"><strong>Solution appears correct!</strong></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: album, great, just, music, cd, book, good, like, movie, quot\n",
      "Cluster 1: great, camera, pictures, lens, use, digital, canon, quality, battery, flash\n",
      "Cluster 2: great, just, does, work, use, product, used, easy, program, software\n"
     ]
    }
   ],
   "source": [
    "summaries = compute_cluster_summaries(kmeans, vectorizer, 10)\n",
    "\n",
    "assert isinstance(summaries, list) and len(summaries) == 3, \"Return value should be a list of length 3 (the number of clusters)\"\n",
    "assert all(len(summary) == 10 for summary in summaries), \"Each list should contain exactly 10 terms\"\n",
    "assert all(isinstance(term, str) for s in summaries for term in s), \"Each list should contain strings\"\n",
    "success()\n",
    "\n",
    "for idx, terms in enumerate(summaries):\n",
    "    print(f\"Cluster {idx}: {', '.join(terms)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Once you have computed the cluster summaries, take a minute to reflect on their quality. Is it clear what the reviews in a given cluster are about? Do the cluster summaries contain any unexpected terms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Problem 3: Compare clusterings using the Rand index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In some scenarios, you may have gold-standard class labels available for at least a subset of your documents. In these cases you can compute the **Rand index** of a clustering, and use this measure to compare the quality of different clusterings.\n",
    "\n",
    "To compute the Rand index, we view a clustering as a binary classifier on (unordered) pairs of documents. The classifier predicts &lsquo;positive&rsquo; if and only if the two documents belong to the same cluster. The (non-normalized) Rand index of the clustering is the accuracy of this classifier relative to a reference in which a document pair belongs to the &lsquo;positive&rsquo; class if and only if the two documents in the pair have the same gold-standard class label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task 3.1\n",
    "\n",
    "Implement a function that computes the Rand index ‚Äúmanually‚Äù, i.e., _without_ importing an external function from a library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31d1156b7fe04f427a13c7b312e6ef03",
     "grade": false,
     "grade_id": "cell-76954c34414f243d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "solution"
    ],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def rand_index(pred_labels, gold_labels):\n",
    "    \"\"\"Compute the Rand index.\n",
    "\n",
    "    Arguments:\n",
    "        pred_labels: The predicted labels.\n",
    "        gold_labels: The gold-standard labels.\n",
    "\n",
    "    Returns:\n",
    "        The Rand index (a single number).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    c = list(combinations(range(len(gold_labels)), 2))\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for i in range(len(c)):\n",
    "        true_pair = gold_labels[c[i][0]]==gold_labels[c[i][1]]\n",
    "        pred_pair = pred_labels[c[i][0]]==pred_labels[c[i][1]]\n",
    "        if true_pair==pred_pair and true_pair == True:\n",
    "            TP += 1\n",
    "        elif true_pair==pred_pair and true_pair == False:\n",
    "            TN += 1\n",
    "        elif true_pair!=pred_pair and true_pair == True:\n",
    "            FN += 1\n",
    "        elif true_pair!=pred_pair and true_pair == False:\n",
    "            FP += 1\n",
    "    rand_index = (TP+TN)/(TP+TN+FP+FN)\n",
    "    return rand_index\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### ü§û Test your code\n",
    "\n",
    "The following cell computes the Rand index on some ‚Äútoy‚Äù examples to check if your implementation is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4de223b4bd77bb39a629bcecb211fff6",
     "grade": true,
     "grade_id": "cell-c7bdeb650dcffdc0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div class=\"alert alert-success\"><strong>Solution appears correct!</strong></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert rand_index([0, 0, 0], [0, 1, 2]) == 0.0\n",
    "assert rand_index([1, 2, 0], [0, 1, 2]) == 1.0\n",
    "assert rand_index([1, 2, 1, 2], [0, 1, 2, 2]) == 0.5\n",
    "success()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task 3.2\n",
    "\n",
    "Using your implementation of the Rand index, compare the performance of different k-means clusters with $k \\in \\{1,2,3,5,7\\}$ clusters. As your evaluation data, use the first 500 documents from the original data set along with their gold-standard categories (from the `category` column).\n",
    "\n",
    "Your implementation should print the computed Rand index for each of the values for $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f80b627a09960efb60af3b56678a802",
     "grade": true,
     "grade_id": "cell-66890753e9a48887",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "solution"
    ],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOALI72\\Anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K =  1  Rand index =  0.16626052104208416\n",
      "K =  2  Rand index =  0.3138196392785571\n",
      "K =  3  Rand index =  0.4466452905811623\n",
      "K =  5  Rand index =  0.6833827655310621\n",
      "K =  7  Rand index =  0.7616993987975952\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "k_set = [1,2,3,5,7]\n",
    "gold_labels = df[0:500]['category']\n",
    "for i in k_set:\n",
    "    kmeans=KMeans(n_clusters=i, random_state=0).fit(reviews)\n",
    "    clusters = kmeans.predict(reviews[0:500])\n",
    "    rand_index_new = rand_index(gold_labels, clusters)\n",
    "    print('K = ', i ,' Rand index = ',rand_index_new)\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Give a brief summary of your results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3fa53fcb38d0309276a8689dd70eb169",
     "grade": true,
     "grade_id": "cell-ef200b0b79192210",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "YOUR ANSWER HERE:\n",
    "In general The Rand index is a measure used to evaluate the similarity between two clusterings and provides a measure of how well a clustering algorithm aligns with known class labels.\n",
    "* A Rand index close to 1 indicates high similarity between the clustering and the reference our gold-standard class.\n",
    "* A Rand index close to 0 suggests that the clustering does not agree with the reference clustering.\n",
    "\n",
    "##### In our case:\n",
    "K =  1  Rand index =  0.166 Suggest clustering does not agree with the reference clustering.\n",
    "K =  2  Rand index =  0.313 Suggest clustering does not agree with the reference clustering\n",
    "K =  3  Rand index =  0.689 Suggest high similarity between the clustering and the reference\n",
    "K =  5  Rand index =  0.683 Suggest high similarity between the clustering and the reference\n",
    "K =  7  Rand index =  0.756 Suggest high similarity between the clustering and the reference\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Problem 4: Train a topic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data set for the topic modelling part of this lab is the collection of all [State of the Union](https://en.wikipedia.org/wiki/State_of_the_Union) addresses from the years 1975‚Äì2000. These speeches come as a single text file with one sentence per line. The following code cell prints the first 5 lines from the data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5e5be2b47aae266f8df5e3f7fca032e",
     "grade": false,
     "grade_id": "cell-a711c6fabeaeae3e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr speaker mr vice president members of the 94th congress and distinguished guests\n",
      "twenty six years ago a freshman congressman a young fellow with lots of idealism who was out to change the world stood before sam rayburn in the well of the house and solemnly swore to the same oath that all of you took yesterday an unforgettable experience and i congratulate you all\n",
      "two days later that same freshman stood at the back of this great chamber over there someplace as president truman all charged up by his single handed election victory reported as the constitution requires on the state of the union\n",
      "when the bipartisan applause stopped president truman said i am happy to report to this 81st congress that the state of the union is good our nation is better able than ever before to meet the needs of the american people and to give them their fair chance in the pursuit of happiness it is foremost among the nations of the world in the search for peace\n",
      "today that freshman member from michigan stands where mr truman stood and i must say to you that the state of the union is not good\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "with open('sotu_1975_2000.txt') as source:\n",
    "    # Print the first 5 lines only\n",
    "    for line in islice(source, 5):\n",
    "        print(line.rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Take a few minutes to think about what topics you would expect in this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task 4.1\n",
    "\n",
    "Your first task on the topic modelling data is to train an LDA model. For this task you will be using [spaCy](https://spacy.io/) and the [gensim](https://radimrehurek.com/gensim/) topic modelling library.\n",
    "\n",
    "Start by preprocessing the data using spaCy.  Filter out stop words, non-alphabetic tokens, and tokens less than 3 characters in length. Store the documents as a nested list where the first level of nesting corresponds to the sentences and the second level corresponds to the tokens in each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner', 'textcat'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16b4a664e4f2a13ff57f5b040448b063",
     "grade": false,
     "grade_id": "cell-201e607b610e47af",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def load_and_preprocess_documents(filename=\"sotu_1975_2000.txt\"):\n",
    "    \"\"\"Load and preprocess all documents in the given file.\n",
    "\n",
    "    The preprocessing must filter out stop words, non-alphabetic tokens,\n",
    "    and tokens less than 3 characters in length.\n",
    "\n",
    "    Returns:\n",
    "        A list of length n, where n is the number of documents.\n",
    "        Each item in the list should be a list of tokens in the given\n",
    "        document, after preprocessing.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    documents = []\n",
    "    with open(\"sotu_1975_2000.txt\") as source:\n",
    "        for line in source:\n",
    "            tokens = []\n",
    "            doc = nlp(line)\n",
    "            for token in doc:\n",
    "                if not token.is_stop and token.is_alpha and len(token) >= 3:\n",
    "                    tokens.append(token.text)\n",
    "            documents.append(tokens)\n",
    "    return documents\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### ü§û Test your code\n",
    "\n",
    "Test your preprocessing by running the following cell. It will output the tokens (after preprocessing) for an example document and compare them against the expected output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "229dff2225112ff17f3aa598dd5145da",
     "grade": true,
     "grade_id": "cell-4fa26bc22c42b359",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document  0 after preprocessing: speaker vice president members congress distinguished guests\n",
      "document 42 after preprocessing: reduce oil imports million barrels day end year million barrels day end\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div class=\"alert alert-success\"><strong>Solution appears correct!</strong></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "documents = load_and_preprocess_documents()\n",
    "\n",
    "assert len(documents) == 2898, \"The number of documents should equal the number of lines in the input file\"\n",
    "print(f\"document  0 after preprocessing: {' '.join(documents[0])}\")\n",
    "assert \" \".join(documents[0]) == \"speaker vice president members congress distinguished guests\"\n",
    "print(f\"document 42 after preprocessing: {' '.join(documents[42])}\")\n",
    "assert \" \".join(documents[42]) == \"reduce oil imports million barrels day end year million barrels day end\", \"The output for document 42 does not appear to be correct\"\n",
    "success()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task 4.2\n",
    "\n",
    "Now that you have the list of documents, skim the section [Pre-process and vectorize the documents](https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html#pre-process-and-vectorize-the-documents) of the gensim documentation to learn how to create the dictionary and the vectorized corpus representation required by gensim. _(Note that you cannot use the standard scikit-learn pipeline in this case.)_ Then, write code to train an [LdaModel](https://radimrehurek.com/gensim/models/ldamodel.html) for $k=10$ topics, and using default values for all other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import Phrases\n",
    "\n",
    "# Ref: https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html#pre-process-and-vectorize-the-documents\n",
    "\n",
    "def train_lda_model(documents, num_topics, passes=1):\n",
    "    \"\"\"Create and train an LDA model.\n",
    "\n",
    "    Arguments:\n",
    "        documents: The preprocessed documents, as produced in Task 4.1.\n",
    "        num_topics: The number of topics to generate.\n",
    "        passes: The number of training passes. Defaults to 1; you will need\n",
    "                this later for Task 5.\n",
    "\n",
    "    Returns:\n",
    "        The trained LDA model.\n",
    "    \"\"\"\n",
    "    # Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "    bigram = Phrases(documents, min_count=20)\n",
    "    for idx in range(len(documents)):\n",
    "        for token in bigram[documents[idx]]:\n",
    "            if '_' in token:\n",
    "                documents[idx].append(token)\n",
    "    # Remove rare and common tokens.\n",
    "    # Create a dictionary representation of the documents.\n",
    "    dictionary = Dictionary(documents)\n",
    "    # Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "    dictionary.filter_extremes(no_below=20, no_above=0.5)\n",
    "    # Bag-of-words representation of the documents.\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
    "    # Train LDA model.\n",
    "    # Make an index to word dictionary.\n",
    "    temp = dictionary[0] # This is only to \"load\" the dictionary.\n",
    "    id2word = dictionary.id2token\n",
    "    model = LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=id2word,\n",
    "        num_topics=num_topics,\n",
    "        passes=passes,\n",
    "    )\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### ü§û Test your code\n",
    "\n",
    "Run the following cell to test your code and print the topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fcf6eedb85c6fecb5c6dc7f7d441af6b",
     "grade": false,
     "grade_id": "cell-5380fd6f4446aa21",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[(0,\n  '0.020*\"world\" + 0.017*\"america\" + 0.014*\"congress\" + 0.014*\"states\" + 0.012*\"year\" + 0.012*\"united\" + 0.011*\"federal\" + 0.011*\"new\" + 0.010*\"people\" + 0.010*\"united_states\"'),\n (1,\n  '0.019*\"year\" + 0.018*\"care\" + 0.016*\"child\" + 0.014*\"world\" + 0.014*\"children\" + 0.013*\"new\" + 0.012*\"tonight\" + 0.012*\"work\" + 0.010*\"health\" + 0.009*\"america\"'),\n (2,\n  '0.032*\"government\" + 0.021*\"people\" + 0.018*\"security\" + 0.018*\"years\" + 0.017*\"social\" + 0.016*\"social_security\" + 0.013*\"budget\" + 0.012*\"american\" + 0.010*\"economic\" + 0.010*\"work\"'),\n (3,\n  '0.022*\"world\" + 0.020*\"america\" + 0.018*\"peace\" + 0.016*\"years\" + 0.015*\"crime\" + 0.015*\"new\" + 0.014*\"work\" + 0.013*\"thank\" + 0.012*\"states\" + 0.011*\"efforts\"'),\n (4,\n  '0.032*\"people\" + 0.020*\"children\" + 0.020*\"work\" + 0.018*\"new\" + 0.015*\"congress\" + 0.015*\"america\" + 0.014*\"americans\" + 0.014*\"know\" + 0.012*\"year\" + 0.011*\"american\"'),\n (5,\n  '0.016*\"help\" + 0.015*\"years\" + 0.014*\"congress\" + 0.014*\"work\" + 0.012*\"tax\" + 0.011*\"cut\" + 0.011*\"support\" + 0.011*\"way\" + 0.011*\"family\" + 0.011*\"people\"'),\n (6,\n  '0.023*\"new\" + 0.023*\"americans\" + 0.019*\"health\" + 0.016*\"people\" + 0.014*\"america\" + 0.014*\"care\" + 0.013*\"years\" + 0.012*\"jobs\" + 0.012*\"year\" + 0.012*\"insurance\"'),\n (7,\n  '0.021*\"america\" + 0.016*\"new\" + 0.014*\"american\" + 0.011*\"nuclear\" + 0.011*\"year\" + 0.010*\"weapons\" + 0.009*\"world\" + 0.009*\"people\" + 0.008*\"nation\" + 0.008*\"time\"'),\n (8,\n  '0.024*\"schools\" + 0.021*\"america\" + 0.016*\"year\" + 0.014*\"budget\" + 0.014*\"college\" + 0.012*\"new\" + 0.011*\"cuts\" + 0.011*\"years\" + 0.011*\"world\" + 0.010*\"school\"'),\n (9,\n  '0.023*\"america\" + 0.017*\"century\" + 0.015*\"let\" + 0.013*\"children\" + 0.013*\"national\" + 0.012*\"government\" + 0.012*\"years\" + 0.010*\"know\" + 0.010*\"responsibility\" + 0.010*\"year\"')]"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = train_lda_model(documents, 10)\n",
    "model.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Inspect the topics. Can you &lsquo;label&rsquo; each topic with a short description of what it is about? Do the topics match your expectations?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The outcomes reveal the specified number of topics, set at 10 in our case. Examining the results, each topic is a cluster of terms that tend to co-occur within the documents provided to the model. The numerical values associated with each term signify their relative importance within the topic, with higher numbers indicating greater significance.\n",
    "For instance, when considering the topics, particularly the first and second terms, we encounter terms such as \"America,\" \"New,\" \"Years,\" \"World,\" \"Congress,\" and others. To me, these topics appear to be related to America, potentially involving congressional matters. Considering the dataset's description ‚Äì \"State of the Union,\" an annual address by the U.S. President to Congress ‚Äì the model's output aligns well. The State of the Union Address typically covers reports on the nation's budget, economy, news, agenda, progress, achievements, and the president's priorities and legislative proposals. Therefore, it is logical to observe results suggesting topics aligned with the themes mentioned."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Problem 5: Monitor a topic model for convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "When learning an LDA model, it is important to make sure that the training algorithm has converged to a stable posterior distribution. One way to do so is to plot, after each training epochs (or &lsquo;pass&rsquo;, in gensim parlance) the log likelihood of the training data under the posterior. Your last task in this lab is to create such a plot and, based on this, to suggest an appropriate number of epochs.\n",
    "\n",
    "To collect information about the posterior likelihood after each pass, we need to enable the logging facilities of gensim. Once this is done, gensim will add various diagnostics to a log file `gensim.log`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "093903f08ea645072cd835d7f07f39b5",
     "grade": false,
     "grade_id": "cell-12010ee79db96ae3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='gensim.log', format='%(asctime)s:%(levelname)s:%(message)s', level=logging.INFO)\n",
    "\n",
    "def clear_logfile():\n",
    "    # To empty the log file\n",
    "    with open(\"gensim.log\", \"w\"):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following function will parse the generated logfile and return the list of log likelihoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35ed9c5af32a1a9a3891e7c4643c55e0",
     "grade": false,
     "grade_id": "cell-0bd244fbb805ee5d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_logfile():\n",
    "    \"\"\"Parse gensim.log to extract the log-likelihood scores.\n",
    "\n",
    "    Returns:\n",
    "        A list of log-likelihood scores.\n",
    "    \"\"\"\n",
    "    matcher = re.compile('(-*\\d+\\.\\d+) per-word .* (\\d+\\.\\d+) perplexity')\n",
    "    likelihoods = []\n",
    "    with open('gensim.log') as source:\n",
    "        for line in source:\n",
    "            match = matcher.search(line)\n",
    "            if match:\n",
    "                likelihoods.append(float(match.group(1)))\n",
    "    return likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here's an example how to run it ‚Äî note that we call `clear_logfile()` to empty the logfile before training the model. If your code from problem 4 was correct, the result should be a list with a single log-likehoodscore, since we are doing a single training pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.865]\n"
     ]
    }
   ],
   "source": [
    "clear_logfile()\n",
    "model = train_lda_model(documents, 10, passes=1)\n",
    "likelihoods = parse_logfile()\n",
    "print(likelihoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task 5.1\n",
    "\n",
    "Your task now is to write re-train your LDA model for 50&nbsp;passes, retrieve the list of log likelihoods, and create a plot from this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19d9b6f7d4470539e80e448e546f73c8",
     "grade": true,
     "grade_id": "cell-e863fa5ab8cd3443",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "solution"
    ],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_likelihoods(likelihoods):\n",
    "    \"\"\"Produce & display a plot of the log-likelihood scores during training.\n",
    "\n",
    "    Arguments:\n",
    "        likelihoods: A list of scores, as returned by `parse_logfile()`.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return plt.plot(likelihoods,color='#2E9947')\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### ü§û Test your code\n",
    "\n",
    "Once you've implemented the plotting function, you can run the LDA model with 50 passes (this will take a moment) and plot the resulting scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e37e37873ac2ebb1292eb2b076d2b7d1",
     "grade": false,
     "grade_id": "cell-c7b05ddd48f08892",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x232e9a3a580>]"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clear_logfile()\n",
    "model = train_lda_model(documents, 10, passes=50)\n",
    "likelihoods = parse_logfile()\n",
    "plot_likelihoods(likelihoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task 5.2\n",
    "\n",
    "How do you interpret the plot you produced in Task 5.1? Based on the plot, what would be a reasonable choice for the number of passes? Retrain your LDA model with that number and re-inspect the topics it finds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca1784a4dd4357b0958b6b854d06f209",
     "grade": true,
     "grade_id": "cell-8435567308839ce2",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[(0,\n  '0.101*\"federal_government\" + 0.096*\"past_years\" + 0.084*\"long_term\" + 0.072*\"health_insurance\" + 0.068*\"economic_growth\" + 0.031*\"federal_government_federal_government\" + 0.026*\"years\" + 0.022*\"federal\" + 0.021*\"government\" + 0.019*\"economic_growth_economic_growth\"'),\n (1,\n  '0.068*\"balanced_budget\" + 0.043*\"white_house\" + 0.040*\"low_income\" + 0.031*\"children\" + 0.025*\"god_bless\" + 0.016*\"schools\" + 0.015*\"families\" + 0.015*\"budget\" + 0.015*\"year\" + 0.014*\"thank\"'),\n (2,\n  '0.035*\"america\" + 0.031*\"ask_congress\" + 0.027*\"tax_credit\" + 0.021*\"world\" + 0.021*\"new\" + 0.020*\"people\" + 0.013*\"americans\" + 0.012*\"nation\" + 0.011*\"century\" + 0.011*\"work\"'),\n (3,\n  '0.241*\"social_security\" + 0.111*\"social_security_social_security\" + 0.099*\"human_rights\" + 0.066*\"took_office\" + 0.050*\"social\" + 0.041*\"security\" + 0.028*\"human_rights_human_rights\" + 0.016*\"rights\" + 0.015*\"human\" + 0.013*\"took\"'),\n (4,\n  '0.230*\"american_people\" + 0.097*\"state_union\" + 0.085*\"vice_president\" + 0.051*\"fellow_citizens\" + 0.045*\"american_people_american_people\" + 0.031*\"people\" + 0.029*\"american\" + 0.027*\"state_union_state_union\" + 0.020*\"president\" + 0.018*\"union\"'),\n (5,\n  '0.319*\"united_states\" + 0.075*\"united_states_united_states\" + 0.062*\"men_women\" + 0.047*\"common_sense\" + 0.043*\"states\" + 0.042*\"united\" + 0.041*\"persian_gulf\" + 0.027*\"men_women_men_women\" + 0.017*\"united_states_united_states_united_states\" + 0.015*\"women\"'),\n (6,\n  '0.159*\"years_ago\" + 0.085*\"soviet_union\" + 0.071*\"cold_war\" + 0.070*\"members_congress\" + 0.053*\"interest_rates\" + 0.049*\"nuclear_weapons\" + 0.029*\"years_ago_years_ago\" + 0.023*\"nuclear\" + 0.021*\"ago\" + 0.020*\"interest_rates_interest_rates\"'),\n (7,\n  '0.098*\"health_care\" + 0.036*\"health_care_health_care\" + 0.028*\"health\" + 0.026*\"care\" + 0.023*\"state_local\" + 0.015*\"education\" + 0.014*\"congress\" + 0.013*\"programs\" + 0.012*\"year\" + 0.011*\"federal\"'),\n (8,\n  '0.037*\"middle_east\" + 0.026*\"foreign_policy\" + 0.023*\"national_security\" + 0.016*\"new\" + 0.013*\"energy\" + 0.011*\"policy\" + 0.010*\"trade\" + 0.010*\"program\" + 0.010*\"security\" + 0.010*\"national\"'),\n (9,\n  '0.078*\"private_sector\" + 0.073*\"fellow_americans\" + 0.051*\"young_people\" + 0.046*\"welfare_reform\" + 0.027*\"welfare\" + 0.021*\"work\" + 0.019*\"people\" + 0.018*\"crime\" + 0.015*\"americans\" + 0.014*\"jobs\"')]"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "model = train_lda_model(documents, 10,passes=25)\n",
    "model.print_topics()\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Write a **brief** paragraph explaining how you chose the number of passes, and whether or not you consider the new topics to be &lsquo;better&rsquo; than the ones that you got from the 1-pass model in Problem&nbsp;4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b0703001a1b39ac3f3130c1d8f7a1c8",
     "grade": true,
     "grade_id": "cell-4830420c2012bd98",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The likelihood graph indicates an enhancement in likelihood as the number of passes increases. Opting for more than 10 passes notably refines our topic modeling. In the instance above, we chose 25 passes, resulting in an intriguing transformation of topics with added contextual depth. Notably, topics now encompass themes such as Human Rights, Congress Members, Soviet Union (typical USA :D), Balanced Budget, Federal Government, Social Security, Foreign Policy, Interest Rate, Health Care, and the Private Sector. These topics align with what one would expect in a typical presidential address to Congress, capturing a diverse range of significant subjects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125ccdbd-4375-4d2f-8b1d-f47097ef2e84",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Congratulations on finishing this lab! üëç**\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "‚û°Ô∏è Don't forget to **test that everything runs as expected** before you submit!\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}